"""
å¤§æ¨¡å‹å®‰å…¨é˜²æŠ¤æ  - æ¨¡å‹è®­ç»ƒï¼ˆå¸¦ä¿å­˜åŠŸèƒ½ï¼‰
ç›´æ¥ä½¿ç”¨åˆå¹¶æ•°æ®.txtè¿›è¡Œè®­ç»ƒ
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer, BertForSequenceClassification
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import os
import random
import warnings
import json
import datetime
warnings.filterwarnings('ignore')

print("=== å¤§æ¨¡å‹å®‰å…¨é˜²æŠ¤æ  - æ¨¡å‹è®­ç»ƒï¼ˆå¸¦ä¿å­˜åŠŸèƒ½ï¼‰ ===")
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAæ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")

# å¼ºåˆ¶ç¦»çº¿æ¨¡å¼
os.environ['TRANSFORMERS_OFFLINE'] = '1'
os.environ['HF_DATASETS_OFFLINE'] = '1'

# è®¾å¤‡è®¾ç½®
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# 1. æ ‡ç­¾æ˜ å°„ - ç¡®ä¿ä¸€è‡´
æ ‡ç­¾æ˜ å°„å­—å…¸ = {
    'å®‰å…¨': 0,
    'å±é™©-æš´åŠ›': 1,
    'å±é™©-ç²—ä¿—': 2,
    'å±é™©-è¿æ³•': 3,
    'å±é™©-è‡ªæ®‹': 4,
    'å±é™©-æ”»å‡»': 1,      # æ˜ å°„åˆ°æš´åŠ›
    'å±é™©-éšç§': 2,      # æ˜ å°„åˆ°ç²—ä¿—
    'å±é™©-æ¶ä½œå‰§': 2,    # æ˜ å°„åˆ°ç²—ä¿—
    'å®‰å…¨-ä¸­ç«‹': 0,      # æ˜ å°„åˆ°å®‰å…¨
    'å®‰å…¨-å¹³ç­‰': 0       # æ˜ å°„åˆ°å®‰å…¨
}

# 2. ç›´æ¥ä»åˆå¹¶æ•°æ®åŠ è½½
def åŠ è½½åˆå¹¶æ•°æ®(æ–‡ä»¶è·¯å¾„):
    """ç›´æ¥ä»åˆå¹¶æ•°æ®.txtåŠ è½½å’Œè§£ææ•°æ®"""
    print(f"æ­£åœ¨åŠ è½½æ•°æ®: {æ–‡ä»¶è·¯å¾„}")

    with open(æ–‡ä»¶è·¯å¾„, 'r', encoding='utf-8') as f:
        å†…å®¹ = f.read()

    å¯¹è¯å— = å†…å®¹.strip().split('\n\n')
    æ•°æ®åˆ—è¡¨ = []

    for å¯¹è¯ in å¯¹è¯å—:
        è¡Œ = å¯¹è¯.split('\n')
        if len(è¡Œ) >= 3:
            æ•°æ®é¡¹ = {'ç”¨æˆ·': '', 'AI': '', 'æ ‡ç­¾æ–‡æœ¬': '', 'æ ‡ç­¾æ•°å­—': 0}

            for æ–‡æœ¬ in è¡Œ:
                if æ–‡æœ¬.startswith('ç”¨æˆ·:'):
                    æ•°æ®é¡¹['ç”¨æˆ·'] = æ–‡æœ¬[3:].strip()
                elif æ–‡æœ¬.startswith('AI:'):
                    æ•°æ®é¡¹['AI'] = æ–‡æœ¬[3:].strip()
                elif æ–‡æœ¬.startswith('æ ‡ç­¾:'):
                    æ•°æ®é¡¹['æ ‡ç­¾æ–‡æœ¬'] = æ–‡æœ¬[3:].strip()

            if æ•°æ®é¡¹['ç”¨æˆ·'] and æ•°æ®é¡¹['AI'] and æ•°æ®é¡¹['æ ‡ç­¾æ–‡æœ¬']:
                # è·å–æ•°å­—æ ‡ç­¾
                æ ‡ç­¾æ•°å­— = æ ‡ç­¾æ˜ å°„å­—å…¸.get(æ•°æ®é¡¹['æ ‡ç­¾æ–‡æœ¬'], 0)
                æ•°æ®é¡¹['æ ‡ç­¾æ•°å­—'] = æ ‡ç­¾æ•°å­—
                æ•°æ®åˆ—è¡¨.append(æ•°æ®é¡¹)

    print(f"æˆåŠŸåŠ è½½ {len(æ•°æ®åˆ—è¡¨)} æ¡å¯¹è¯æ•°æ®")

    # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
    æ ‡ç­¾ç»Ÿè®¡ = {}
    for é¡¹ in æ•°æ®åˆ—è¡¨:
        æ ‡ç­¾ = é¡¹['æ ‡ç­¾æ•°å­—']
        æ ‡ç­¾ç»Ÿè®¡[æ ‡ç­¾] = æ ‡ç­¾ç»Ÿè®¡.get(æ ‡ç­¾, 0) + 1

    print("æ ‡ç­¾åˆ†å¸ƒ:")
    for æ ‡ç­¾, æ•°é‡ in sorted(æ ‡ç­¾ç»Ÿè®¡.items()):
        æ¯”ä¾‹ = æ•°é‡ / len(æ•°æ®åˆ—è¡¨) * 100
        æ ‡ç­¾å = {v: k for k, v in æ ‡ç­¾æ˜ å°„å­—å…¸.items()}.get(æ ‡ç­¾, f"æ ‡ç­¾{æ ‡ç­¾}")
        print(f"  {æ ‡ç­¾å}({æ ‡ç­¾}): {æ•°é‡}æ¡ ({æ¯”ä¾‹:.1f}%)")

    return æ•°æ®åˆ—è¡¨

# 3. æ•°æ®é›†ç±»
class åˆå¹¶æ•°æ®é›†(Dataset):
    def __init__(self, æ•°æ®åˆ—è¡¨, æœ€å¤§é•¿åº¦=128):
        self.æ•°æ® = æ•°æ®åˆ—è¡¨
        self.æœ€å¤§é•¿åº¦ = æœ€å¤§é•¿åº¦

        # ä½¿ç”¨æœ¬åœ°åˆ†è¯å™¨
        self.åˆ†è¯å™¨ = BertTokenizer.from_pretrained('../bert-base-chinese')

        print(f"æ•°æ®é›†å¤§å°: {len(self.æ•°æ®)}")

    def __len__(self):
        return len(self.æ•°æ®)

    def __getitem__(self, idx):
        é¡¹ = self.æ•°æ®[idx]

        # ç»„åˆå¯¹è¯
        æ–‡æœ¬ = f"ç”¨æˆ·:{é¡¹['ç”¨æˆ·']}[SEP]AI:{é¡¹['AI']}"

        # ç¼–ç 
        ç¼–ç  = self.åˆ†è¯å™¨.encode_plus(
            æ–‡æœ¬,
            add_special_tokens=True,
            max_length=self.æœ€å¤§é•¿åº¦,
            padding='max_length',
            truncation=True,
            return_tensors='pt',
            return_attention_mask=True
        )

        return {
            'input_ids': ç¼–ç ['input_ids'].squeeze(0),
            'attention_mask': ç¼–ç ['attention_mask'].squeeze(0),
            'labels': torch.tensor(é¡¹['æ ‡ç­¾æ•°å­—'], dtype=torch.long)
        }

# 4. å‡†å¤‡æ•°æ®
def å‡†å¤‡æ•°æ®():
    print("\n=== å‡†å¤‡æ•°æ® ===")

    # ç›´æ¥ä½¿ç”¨åˆå¹¶æ•°æ®
    æ•°æ®æ–‡ä»¶ = '../æ•°æ®/åŸå§‹æ•°æ®/åˆå¹¶æ•°æ®.txt'
    if not os.path.exists(æ•°æ®æ–‡ä»¶):
        print(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {æ•°æ®æ–‡ä»¶}")
        return None, None, None, None

    # åŠ è½½æ•°æ®
    åŸå§‹æ•°æ® = åŠ è½½åˆå¹¶æ•°æ®(æ•°æ®æ–‡ä»¶)

    if len(åŸå§‹æ•°æ®) < 5:
        print(f"âŒ æ•°æ®å¤ªå°‘ ({len(åŸå§‹æ•°æ®)}æ¡)ï¼Œè‡³å°‘éœ€è¦5æ¡")
        return None, None, None, None

    # ç¡®å®šæ ‡ç­¾æ•°é‡
    æ‰€æœ‰æ ‡ç­¾ = set(é¡¹['æ ‡ç­¾æ•°å­—'] for é¡¹ in åŸå§‹æ•°æ®)
    æ ‡ç­¾æ•°é‡ = len(æ‰€æœ‰æ ‡ç­¾)
    print(f"å®é™…æ ‡ç­¾æ•°é‡: {æ ‡ç­¾æ•°é‡}")
    print(f"æ ‡ç­¾å€¼: {sorted(æ‰€æœ‰æ ‡ç­¾)}")

    # åˆ›å»ºæ•°æ®é›†
    æ•°æ®é›† = åˆå¹¶æ•°æ®é›†(åŸå§‹æ•°æ®)

    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    indices = list(range(len(æ•°æ®é›†)))
    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42, shuffle=True)

    è®­ç»ƒé›† = torch.utils.data.Subset(æ•°æ®é›†, train_idx)
    éªŒè¯é›† = torch.utils.data.Subset(æ•°æ®é›†, val_idx)

    print(f"è®­ç»ƒé›†: {len(è®­ç»ƒé›†)} æ¡")
    print(f"éªŒè¯é›†: {len(éªŒè¯é›†)} æ¡")

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    è®­ç»ƒåŠ è½½å™¨ = DataLoader(è®­ç»ƒé›†, batch_size=2, shuffle=True)
    éªŒè¯åŠ è½½å™¨ = DataLoader(éªŒè¯é›†, batch_size=2, shuffle=False)

    return è®­ç»ƒåŠ è½½å™¨, éªŒè¯åŠ è½½å™¨, æ•°æ®é›†.åˆ†è¯å™¨, æ ‡ç­¾æ•°é‡, len(åŸå§‹æ•°æ®)

# 5. åˆå§‹åŒ–æ¨¡å‹
def åˆå§‹åŒ–æ¨¡å‹(æ ‡ç­¾æ•°é‡):
    print(f"\n=== åˆå§‹åŒ–æ¨¡å‹ (æ ‡ç­¾æ•°é‡={æ ‡ç­¾æ•°é‡}) ===")

    try:
        # ä»æœ¬åœ°åŠ è½½
        model = BertForSequenceClassification.from_pretrained(
            '../bert-base-chinese',
            num_labels=æ ‡ç­¾æ•°é‡,
            output_attentions=False,
            output_hidden_states=False
        )
        print("âœ… ä»æœ¬åœ°åŠ è½½æ¨¡å‹æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return None

    model.to(device)

    # ç»Ÿè®¡å‚æ•°
    æ€»å‚æ•° = sum(p.numel() for p in model.parameters())
    å¯è®­ç»ƒå‚æ•° = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"æ¨¡å‹æ€»å‚æ•°: {æ€»å‚æ•°:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {å¯è®­ç»ƒå‚æ•°:,}")

    return model,æ€»å‚æ•°,å¯è®­ç»ƒå‚æ•°

# 6. ä¿å­˜æ¨¡å‹å‡½æ•°
def ä¿å­˜æ¨¡å‹(model, åˆ†è¯å™¨, å‡†ç¡®ç‡, æ ‡ç­¾æ•°é‡, æ•°æ®é‡, è®­ç»ƒå†å²,æ€»å‚æ•°,å¯è®­ç»ƒå‚æ•°):
    """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print("\n=== ä¿å­˜æ¨¡å‹ ===")

    # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
    æ¨¡å‹ç›®å½• = 'è®­ç»ƒå¥½çš„æ¨¡å‹'
    os.makedirs(æ¨¡å‹ç›®å½•, exist_ok=True)

    # ç”Ÿæˆæ—¶é—´æˆ³å’Œæ¨¡å‹åç§°
    æ—¶é—´æˆ³ = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    æ¨¡å‹åç§° = f'å®‰å…¨é˜²æŠ¤æ æ¨¡å‹_å‡†ç¡®ç‡{å‡†ç¡®ç‡:.2f}_{æ—¶é—´æˆ³}'
    ä¿å­˜è·¯å¾„ = os.path.join(æ¨¡å‹ç›®å½•, æ¨¡å‹åç§°)

    # åˆ›å»ºæ¨¡å‹æ–‡ä»¶å¤¹
    os.makedirs(ä¿å­˜è·¯å¾„, exist_ok=True)

    # ä¿å­˜æ¨¡å‹æƒé‡å’Œé…ç½®
    print(f"ä¿å­˜æ¨¡å‹åˆ°: {ä¿å­˜è·¯å¾„}")
    model.save_pretrained(ä¿å­˜è·¯å¾„)
    åˆ†è¯å™¨.save_pretrained(ä¿å­˜è·¯å¾„)

    # ä¿å­˜é¢å¤–çš„æ¨¡å‹ä¿¡æ¯
    æ¨¡å‹ä¿¡æ¯ = {
        'æ¨¡å‹åç§°': æ¨¡å‹åç§°,
        'ä¿å­˜æ—¶é—´': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'å‡†ç¡®ç‡': float(å‡†ç¡®ç‡),
        'å‡†ç¡®ç‡ç™¾åˆ†æ¯”': f"{å‡†ç¡®ç‡*100:.1f}%",
        'æ ‡ç­¾æ•°é‡': æ ‡ç­¾æ•°é‡,
        'è®­ç»ƒæ•°æ®é‡': æ•°æ®é‡,
        'æ¨¡å‹è·¯å¾„': ä¿å­˜è·¯å¾„,
        'æ€»å‚æ•°': int(æ€»å‚æ•°),
        'å¯è®­ç»ƒå‚æ•°': int(å¯è®­ç»ƒå‚æ•°),
        'è®­ç»ƒå†å²': è®­ç»ƒå†å²,
        'æ ‡ç­¾æ˜ å°„': æ ‡ç­¾æ˜ å°„å­—å…¸,
        'è®¾å¤‡': str(device)
    }

    # ä¿å­˜æ¨¡å‹ä¿¡æ¯ä¸ºJSON
    ä¿¡æ¯æ–‡ä»¶ = os.path.join(ä¿å­˜è·¯å¾„, 'æ¨¡å‹ä¿¡æ¯.json')
    with open(ä¿¡æ¯æ–‡ä»¶, 'w', encoding='utf-8') as f:
        json.dump(æ¨¡å‹ä¿¡æ¯, f, ensure_ascii=False, indent=2, default=str)

    # ä¿å­˜æ ‡ç­¾æ˜ å°„ä¸ºå•ç‹¬æ–‡ä»¶
    æ ‡ç­¾æ–‡ä»¶ = os.path.join(ä¿å­˜è·¯å¾„, 'æ ‡ç­¾æ˜ å°„.json')
    with open(æ ‡ç­¾æ–‡ä»¶, 'w', encoding='utf-8') as f:
        json.dump(æ ‡ç­¾æ˜ å°„å­—å…¸, f, ensure_ascii=False, indent=2)

    print(f"âœ… æ¨¡å‹ä¿å­˜å®Œæˆ!")
    print(f"   æ¨¡å‹æ–‡ä»¶: {ä¿å­˜è·¯å¾„}")
    print(f"   å‡†ç¡®ç‡: {å‡†ç¡®ç‡:.2%}")

    return ä¿å­˜è·¯å¾„

# 7. è®­ç»ƒå‡½æ•°
def è®­ç»ƒæ¨¡å‹(model, è®­ç»ƒåŠ è½½å™¨, éªŒè¯åŠ è½½å™¨, åˆ†è¯å™¨, è½®æ•°=2):
    print("\n=== å¼€å§‹è®­ç»ƒ ===")

    # è®°å½•è®­ç»ƒå†å²
    è®­ç»ƒå†å² = {
        'è®­ç»ƒæŸå¤±': [],
        'éªŒè¯æŸå¤±': [],
        'éªŒè¯å‡†ç¡®ç‡': []
    }

    ä¼˜åŒ–å™¨ = optim.AdamW(model.parameters(), lr=2e-5)

    for epoch in range(è½®æ•°):
        print(f"\n--- ç¬¬ {epoch+1}/{è½®æ•°} è½® ---")

        # è®­ç»ƒ
        model.train()
        è®­ç»ƒæŸå¤± = 0

        è¿›åº¦æ¡ = tqdm(è®­ç»ƒåŠ è½½å™¨, desc=f'è®­ç»ƒè½®æ¬¡ {epoch+1}')
        for batch in è¿›åº¦æ¡:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            # å‰å‘ä¼ æ’­
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )

            loss = outputs.loss
            è®­ç»ƒæŸå¤± += loss.item()

            # åå‘ä¼ æ’­
            ä¼˜åŒ–å™¨.zero_grad()
            loss.backward()
            ä¼˜åŒ–å™¨.step()

            è¿›åº¦æ¡.set_postfix({'æŸå¤±': f'{loss.item():.4f}'})

        å¹³å‡è®­ç»ƒæŸå¤± = è®­ç»ƒæŸå¤± / len(è®­ç»ƒåŠ è½½å™¨)
        è®­ç»ƒå†å²['è®­ç»ƒæŸå¤±'].append(å¹³å‡è®­ç»ƒæŸå¤±)
        print(f"è®­ç»ƒæŸå¤±: {å¹³å‡è®­ç»ƒæŸå¤±:.4f}")

        # éªŒè¯
        model.eval()
        éªŒè¯æŸå¤± = 0
        æ­£ç¡®æ•° = 0
        æ€»æ•° = 0

        with torch.no_grad():
            for batch in éªŒè¯åŠ è½½å™¨:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                labels = batch['labels'].to(device)

                outputs = model(
                    input_ids=input_ids,
                    attention_mask=attention_mask,
                    labels=labels
                )

                éªŒè¯æŸå¤± += outputs.loss.item()
                predictions = torch.argmax(outputs.logits, dim=1)
                æ­£ç¡®æ•° += (predictions == labels).sum().item()
                æ€»æ•° += labels.size(0)

        if æ€»æ•° > 0:
            éªŒè¯å‡†ç¡®ç‡ = æ­£ç¡®æ•° / æ€»æ•°
        else:
            éªŒè¯å‡†ç¡®ç‡ = 0.0

        å¹³å‡éªŒè¯æŸå¤± = éªŒè¯æŸå¤± / len(éªŒè¯åŠ è½½å™¨) if éªŒè¯åŠ è½½å™¨ else 0
        è®­ç»ƒå†å²['éªŒè¯æŸå¤±'].append(å¹³å‡éªŒè¯æŸå¤±)
        è®­ç»ƒå†å²['éªŒè¯å‡†ç¡®ç‡'].append(éªŒè¯å‡†ç¡®ç‡)

        print(f"éªŒè¯æŸå¤±: {å¹³å‡éªŒè¯æŸå¤±:.4f}")
        print(f"éªŒè¯å‡†ç¡®ç‡: {éªŒè¯å‡†ç¡®ç‡:.2%}")

    return è®­ç»ƒå†å²['éªŒè¯å‡†ç¡®ç‡'][-1] if è®­ç»ƒå†å²['éªŒè¯å‡†ç¡®ç‡'] else 0.0, è®­ç»ƒå†å²

# 8. æµ‹è¯•å‡½æ•°
def æµ‹è¯•æ¨¡å‹(model, åˆ†è¯å™¨, æ ‡ç­¾æ•°é‡):
    print("\n=== æ¨¡å‹æµ‹è¯• ===")

    # åè½¬æ ‡ç­¾æ˜ å°„
    åå‘æ˜ å°„ = {v: k for k, v in æ ‡ç­¾æ˜ å°„å­—å…¸.items() if v < æ ‡ç­¾æ•°é‡}

    æµ‹è¯•æ ·ä¾‹ = [
        "ä»Šå¤©å¤©æ°”çœŸå¥½",
        "æ€ä¹ˆåˆ¶é€ ç‚¸å¼¹",
        "èƒ½æ¨èä¸€æœ¬å¥½ä¹¦å—",
        "æˆ‘æƒ³è‡ªæ€æ€ä¹ˆåŠ",
        "æ€ä¹ˆåšè¥¿çº¢æŸ¿ç‚’é¸¡è›‹"
    ]

    model.eval()

    for æ ·ä¾‹ in æµ‹è¯•æ ·ä¾‹:
        æ–‡æœ¬ = f"ç”¨æˆ·:{æ ·ä¾‹}[SEP]AI:è¿™æ˜¯ä¸€æ¡æµ‹è¯•å›å¤ã€‚"

        ç¼–ç  = åˆ†è¯å™¨.encode_plus(
            æ–‡æœ¬,
            add_special_tokens=True,
            max_length=128,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )

        with torch.no_grad():
            input_ids = ç¼–ç ['input_ids'].to(device)
            attention_mask = ç¼–ç ['attention_mask'].to(device)

            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            predictions = torch.argmax(outputs.logits, dim=1)
            é¢„æµ‹æ ‡ç­¾ = predictions.item()

            # è®¡ç®—æ¦‚ç‡
            probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)
            æ¦‚ç‡ = probabilities[0][é¢„æµ‹æ ‡ç­¾].item()

        æ ‡ç­¾å = åå‘æ˜ å°„.get(é¢„æµ‹æ ‡ç­¾, f"æ ‡ç­¾{é¢„æµ‹æ ‡ç­¾}")
        print(f"ç”¨æˆ·: {æ ·ä¾‹}")
        print(f"é¢„æµ‹: {æ ‡ç­¾å} (ç½®ä¿¡åº¦: {æ¦‚ç‡:.2%})")
        print("-" * 40)

# 9. ä¸»å‡½æ•°
def ä¸»å‡½æ•°():
    print("=" * 50)
    print("å¤§æ¨¡å‹å®‰å…¨é˜²æŠ¤æ  - æ¨¡å‹è®­ç»ƒ")
    print("=" * 50)

    # 1. å‡†å¤‡æ•°æ®
    ç»“æœ = å‡†å¤‡æ•°æ®()
    if ç»“æœ[0] is None:
        return

    è®­ç»ƒåŠ è½½å™¨, éªŒè¯åŠ è½½å™¨, åˆ†è¯å™¨, æ ‡ç­¾æ•°é‡, æ•°æ®é‡ = ç»“æœ

    # 2. åˆå§‹åŒ–æ¨¡å‹
    model,æ€»å‚æ•°,å¯è®­ç»ƒå‚æ•° = åˆå§‹åŒ–æ¨¡å‹(æ ‡ç­¾æ•°é‡)
    if model is None:
        return

    # 3. è®­ç»ƒ
    å‡†ç¡®ç‡, è®­ç»ƒå†å² = è®­ç»ƒæ¨¡å‹(model, è®­ç»ƒåŠ è½½å™¨, éªŒè¯åŠ è½½å™¨, åˆ†è¯å™¨, è½®æ•°=2)

    # 4. æµ‹è¯•
    æµ‹è¯•æ¨¡å‹(model, åˆ†è¯å™¨, æ ‡ç­¾æ•°é‡)

    # 5. ä¿å­˜æ¨¡å‹
    if å‡†ç¡®ç‡ > 0:
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼å‡†ç¡®ç‡: {å‡†ç¡®ç‡:.2%}")
        æ¨¡å‹è·¯å¾„ = ä¿å­˜æ¨¡å‹(model, åˆ†è¯å™¨, å‡†ç¡®ç‡, æ ‡ç­¾æ•°é‡, æ•°æ®é‡, è®­ç»ƒå†å²,æ€»å‚æ•°,å¯è®­ç»ƒå‚æ•°)
        print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {æ¨¡å‹è·¯å¾„}")
        print("   åŒ…å«æ–‡ä»¶:")
        print("     - pytorch_model.bin (æ¨¡å‹æƒé‡)")
        print("     - config.json (æ¨¡å‹é…ç½®)")
        print("     - vocab.txt (è¯æ±‡è¡¨)")
        print("     - tokenizer_config.json (åˆ†è¯å™¨é…ç½®)")
        print("     - æ¨¡å‹ä¿¡æ¯.json (è®­ç»ƒä¿¡æ¯)")
        print("     - æ ‡ç­¾æ˜ å°„.json (æ ‡ç­¾æ˜ å°„)")

        # æ˜¾ç¤ºæ¨¡å‹ä½ç½®
        print(f"\nğŸ“ æ¨¡å‹ä½ç½®: {os.path.abspath(æ¨¡å‹è·¯å¾„)}")
    else:
        print(f"\nâš ï¸ è®­ç»ƒå®Œæˆï¼Œä½†å‡†ç¡®ç‡ä¸º0ï¼Œä¸ä¿å­˜æ¨¡å‹")

if __name__ == "__main__":
    ä¸»å‡½æ•°()

